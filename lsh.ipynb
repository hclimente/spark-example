{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T16:55:54.992738Z",
     "start_time": "2017-11-07T16:55:29.040863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.2.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.5.4 (default, Oct 27 2017 11:48:53)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "sparkFile = os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py')\n",
    "exec(compile(open(sparkFile, \"rb\").read(), sparkFile, 'exec'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T16:55:55.021205Z",
     "start_time": "2017-11-07T16:55:54.996218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "['a2i', 'aaa', 'aaai', 'aapo', 'aat', 'aazhang', 'abandonment', 'abbott', 'abbreviated', 'abcde', 'abe', 'abeles', 'abi', 'abilistic', 'abilities', 'ability', 'abl', 'able', 'ables', 'ablex']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = [ word for word in map(lambda x: x.strip(), open(\"data/vocab.nips.txt\").readlines()) ]\n",
    "print('the' in vocabulary or 'a' in vocabulary or 'to' in vocabulary)\n",
    "print(vocabulary[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local-sensitivity hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shingling: the documents as sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T16:55:55.721000Z",
     "start_time": "2017-11-07T16:55:55.024719Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = sc.textFile (\"data/docword.nips.txt\") \\\n",
    "        .map(lambda line: line.split()) \\\n",
    "        .filter(lambda line: len(line) == 3) \\\n",
    "        .map(lambda y: (y[0], int(y[1]) - 1)) \\\n",
    "        .groupByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C is an RDD that represents the characteristic matrix of the dataset. A pair (K,V), represent the rows K of column K, which are the only non-zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhash: getting document signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T16:55:55.755149Z",
     "start_time": "2017-11-07T16:55:55.723686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "A = random.sample(range(1,1500), 100)\n",
    "B = random.sample(range(1,1500), 100)\n",
    "\n",
    "def min_hash(a, b, sig):\n",
    "    hashes = [((a * x) + b) % len(vocabulary) for x in sig]\n",
    "    return min(hashes)\n",
    "\n",
    "def get_signature(p):\n",
    "    doc,words = p\n",
    "    signature = [ min_hash(a, b, words) for a,b in zip(A,B) ]\n",
    "    return((doc, signature))\n",
    "\n",
    "M = C. map(get_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH: getting candidate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T16:55:55.785195Z",
     "start_time": "2017-11-07T16:55:55.758749Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunk(l, n):\n",
    "    l = [ x for x in l ]\n",
    "    for i in range(0, len(l), int(len(l)/n)):\n",
    "        yield frozenset(l[i:i + n])\n",
    "        \n",
    "def hash_bands(p):\n",
    "    doc,sig = p   \n",
    "    bands = [ ((i, hash(b)), doc) for i,b in enumerate(chunk(sig, 10)) ]\n",
    "    return bands\n",
    "    \n",
    "B = M. flatMap(hash_bands)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
